{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matmul Dataflow\n",
    "\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import te \n",
    "# ---------------\n",
    "# op config\n",
    "# ---------------\n",
    "M = 256\n",
    "N = 128\n",
    "K = 512\n",
    "# M = 8\n",
    "# N = 8\n",
    "# K = 4\n",
    "# ---------------\n",
    "# tile size\n",
    "# NOTE: Tunable params\n",
    "# ---------------\n",
    "# dtu.sip (tile) = processor = PX = tvm.parallel\n",
    "# PM = 128\n",
    "# PN = 64\n",
    "# PK = K\n",
    "PM = (M + 1) // 2\n",
    "PN = (N + 1) // 2\n",
    "PK = K\n",
    "# dtu.csb (tile) = global/shared (use global) = CX\n",
    "CM = (PM + 1) // 2\n",
    "CN = (PN + 1) // 2\n",
    "CK = (PK + 1) // 2\n",
    "# dtu.sdb (tile) = local\n",
    "SM = (CM + 1) // 2\n",
    "SN = (CN + 1) // 2\n",
    "SK = (CK + 1) // 2\n",
    "# dtu.kernel\n",
    "KM = 2\n",
    "KN = 2\n",
    "KK = 2\n",
    "\n",
    "# ---------------\n",
    "# define compute\n",
    "# ---------------\n",
    "# define a reduce axis\n",
    "k = te.reduce_axis((0, K), \"k\") \n",
    "\n",
    "# input tensors\n",
    "l = te.placeholder((M, K), name=\"l\")\n",
    "r = te.placeholder((K, N), name=\"r\")\n",
    "# compute\n",
    "o = te.compute((M, N), lambda m, n: te.sum(l[m, k] * r[k, n], axis=k), name=\"o\")\n",
    "\n",
    "# ---------------\n",
    "# schedule op\n",
    "# ---------------\n",
    "# create a schedule\n",
    "s = te.create_schedule(o.op)\n",
    "print(tvm.lower(s, [l, r, o], simple_mode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add DMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add d2c\n",
    "# l_l2 = s.cache_read(l, \"global\", [o])\n",
    "# r_l2 = s.cache_read(r, \"global\", [o])\n",
    "l_l2 = s.cache_read(l, \"shared\", [o])\n",
    "r_l2 = s.cache_read(r, \"shared\", [o])\n",
    "\n",
    "# add c2s\n",
    "# XC - X in cache: global, shared, local\n",
    "l_l1 = s.cache_read(l_l2, \"local\", [o])\n",
    "r_l1 = s.cache_read(r_l2, \"local\", [o])\n",
    "\n",
    "# add c2d\n",
    "o_l2 = s.cache_write(o, \"shared\")\n",
    "\n",
    "# add s2c\n",
    "o_l1 = s.cache_write(o_l2, \"local\")\n",
    "\n",
    "print(tvm.lower(s, [l, r, o], simple_mode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split output-L3 and output-L2\n",
    "\n",
    "_PM_，_PN_ 是指每个SIP并行处理的负载量，从一个SIP的视角看，这并没有切分，是其要处理的全部。\n",
    "\n",
    "_CM_, _CN_ 是 CSB 上的 tiling size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------- dependency graph --------\n",
    "# l -d2c- l_l1 \\ \n",
    "#               o_l1 (compute) -s2c- o_l2 -c2d- o\n",
    "# r -d2c- r_l1 /\n",
    "# we need to determine the stages of a \n",
    "# graph from its leaf (o)\n",
    "# ----------------------------------\n",
    "# tile - sip - o\n",
    "# axis\n",
    "m, n = o.op.axis\n",
    "# split \n",
    "# m\n",
    "m, pm = s[o].split(m, PM)\n",
    "pm, cm = s[o].split(pm, CM)\n",
    "# n\n",
    "n, pn = s[o].split(n, PN)\n",
    "pn, cn = s[o].split(pn, CN)\n",
    "# reorder \n",
    "s[o].reorder(m, n, pm, pn, cm, cn)\n",
    "# insert tensors\n",
    "# s[l_l2].compute_at(s[o], pn)\n",
    "# s[r_l2].compute_at(s[o], pn)\n",
    "# s[l_l1].compute_at(s[o], pn)\n",
    "# s[r_l1].compute_at(s[o], pn)\n",
    "# s[o_l1].compute_at(s[o], pn)\n",
    "s[o_l2].compute_at(s[o], pn)\n",
    "print(tvm.lower(s, [l, r, o], simple_mode=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split output-L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tile - csb - o_l2\n",
    "# axis\n",
    "cm, cn = o_l2.op.axis\n",
    "# split \n",
    "# m\n",
    "cm, sm = s[o_l2].split(cm, SM)\n",
    "# n\n",
    "cn, sn = s[o_l2].split(cn, SN)\n",
    "# reorder \n",
    "s[o_l2].reorder(cm, cn, sm, sn)\n",
    "# insert tensors\n",
    "s[o_l1].compute_at(s[o_l2], cn)\n",
    "print(tvm.lower(s, [l, r, o], simple_mode=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split output-L0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tile - sdb & kernel - o_l1\n",
    "sm, sn = o_l1.op.axis\n",
    "# split\n",
    "# m\n",
    "sm, km = s[o_l1].split(sm, KM)\n",
    "# n\n",
    "sn, kn = s[o_l1].split(sn, KN)\n",
    "# k\n",
    "pk, ck = s[o_l1].split(k, CK)\n",
    "ck, sk = s[o_l1].split(ck, SK)\n",
    "sk, kk = s[o_l1].split(sk, KK)\n",
    "# reorder \n",
    "s[o_l1].reorder(pk, ck, sm, sn, sk, km, kn, kk)\n",
    "\n",
    "# insert tensors\n",
    "s[l_l1].compute_at(s[o_l1], ck)\n",
    "s[r_l1].compute_at(s[o_l1], ck)\n",
    "s[l_l2].compute_at(s[o_l1], pk)\n",
    "s[r_l2].compute_at(s[o_l1], pk)\n",
    "print(tvm.lower(s, [l, r, o], simple_mode=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# parallelize\n",
    "s[o].parallel(m)\n",
    "s[o].parallel(n)\n",
    "print('\\n 6 parallelize outer m, n loops \\n', tvm.lower(s, [l, r, o], simple_mode=True))\n",
    "\n",
    "print('X:', [M, N, K])\n",
    "print('PX:', [PM, PN, PK])\n",
    "print('CX:', [CM, CN, CK])\n",
    "print('SX:', [SM, SN, SK])\n",
    "print('KX:', [KM, KN, KK])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "221bae69870c1675c4cfc152c4d60c3a5cfbb0e1cf1a5072332d9dded6c10f66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
