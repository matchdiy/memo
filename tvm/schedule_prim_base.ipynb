{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Schedule Primitives in TVM](https://tvm.apache.org/docs/how_to/work_with_schedules/schedule_primitives.html#sphx-glr-how-to-work-with-schedules-schedule-primitives-py)\n",
    "\n",
    "## Create Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, print_function\n",
    "\n",
    "\n",
    "import tvm\n",
    "from tvm import te\n",
    "import numpy as np\n",
    "\n",
    "# declare some variables for use later\n",
    "n = te.var(\"n\")\n",
    "m = te.var(\"m\")\n",
    "\n",
    "def test_elewise_mul():\n",
    "  # declare a matrix element-wise multiply\n",
    "  A = te.placeholder((m, n), name=\"A\")\n",
    "  B = te.placeholder((m, n), name=\"B\")\n",
    "  C = te.compute((m, n), lambda i, j: A[i, j] * B[i, j], name=\"C\")\n",
    "\n",
    "  s = te.create_schedule([C.op])\n",
    "  # lower will transform the computation from definition to the real\n",
    "  # callable function. With argument `simple_mode=True`, it will\n",
    "  # return you a readable C like statement, we use it here to print the\n",
    "  # schedule result.\n",
    "  print(tvm.lower(s, [A, B, C], simple_mode=True))\n",
    "\n",
    "test_elewise_mul()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SchedulePrimitives::Split\n",
    "\n",
    "SplitFactor：将指定维度按照指定长度进行切分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split_factor(axis, factor=32):\n",
    "  A = te.placeholder((m, n), name=\"A\")\n",
    "  B = te.compute((m, n), lambda i, j: A[i, j], name=\"B\")\n",
    "  s = te.create_schedule(B.op)\n",
    "  xo, xi = s[B].split(B.op.axis[axis], factor=factor)\n",
    "  print(tvm.lower(s, [A, B], simple_mode=True))\n",
    "\n",
    "test_split_factor(axis=0)\n",
    "test_split_factor(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SplitParts：将指定维度按照指定份数进行切分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split_nparts(nparts=8):\n",
    "  A = te.placeholder((m,), name=\"A\")\n",
    "  B = te.compute((m,), lambda i: A[i], name=\"B\")\n",
    "  s = te.create_schedule(B.op)\n",
    "  bx, tx = s[B].split(B.op.axis[0], nparts=nparts)\n",
    "  print(tvm.lower(s, [A, B], simple_mode=True))\n",
    "\n",
    "test_split_nparts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SchedulePrimitives::Tile\n",
    "\n",
    "分块操作，注意Tile和Split是有区别的，我们无法用两个Split完成一个Tile的功能，但是可以通过Tile覆盖Split功能（Split中不切的axis-factor设为1）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tile(x, y, simple_mode=True):\n",
    "  A = te.placeholder((m, n), name=\"A\")\n",
    "  B = te.compute((m, n), lambda i, j: A[i, j], name=\"B\")\n",
    "  s = te.create_schedule(B.op)\n",
    "  xo, yo, xi, yi = s[B].tile(B.op.axis[0], B.op.axis[1], x_factor=x, y_factor=y)\n",
    "  print(tvm.lower(s, [A, B], simple_mode=simple_mode))\n",
    "\n",
    "test_tile(10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较一下 ___Split___ 和 ___Tile___ 的行为： ___Tile___ 需要 ___Split___ 和 ___Reorder___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split_x2(x_factor, y_factor):\n",
    "  A = te.placeholder((m, n), name=\"A\")\n",
    "  B = te.compute((m, n), lambda i, j: A[i, j], name=\"B\")\n",
    "  s = te.create_schedule(B.op)\n",
    "  xo, xi = s[B].split(B.op.axis[0], factor=x_factor)\n",
    "  yo, yi = s[B].split(B.op.axis[1], factor=y_factor)\n",
    "  print(tvm.lower(s, [A, B], simple_mode=True))\n",
    "\n",
    "print('*'*64)\n",
    "print('test_split_x2(10, 5)')\n",
    "print('*'*64)\n",
    "test_split_x2(10, 5)\n",
    "print('*'*64)\n",
    "print('test_tile(10, 5)')\n",
    "print('*'*64)\n",
    "test_tile(10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较一下 ___Split___ 和 ___Tile___ 的行为：用 ___Tile___ 来实现 ___Split___：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split_factor(axis=1, factor=5)\n",
    "test_tile(1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SchedulePrimitives::Fuse\n",
    "\n",
    "合并连续的 ___N___ 个维度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fuse(axis0, axis1, simple_mode=True):\n",
    "  A = te.placeholder((m, n), name=\"A\")\n",
    "  B = te.compute((m, n), lambda i, j: A[i, j], name=\"B\")\n",
    "  s = te.create_schedule(B.op)\n",
    "  # tile to four axes first: (i.outer, j.outer, i.inner, j.inner)\n",
    "  axes4 = s[B].tile(B.op.axis[0], B.op.axis[1], x_factor=10, y_factor=5)\n",
    "  # then fuse (i.inner, j.inner) into one axis: (i.inner.j.inner.fused)\n",
    "  fused = s[B].fuse(axes4[axis0], axes4[axis1])\n",
    "  ### fused = s[B].fuse(xo, yo)\n",
    "  print(tvm.lower(s, [A, B], simple_mode=simple_mode))\n",
    "\n",
    "test_fuse(1, 2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SchedulePrimitives::Reorder\n",
    "\n",
    "维度调换，相当于Transpose功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_reorder(axis0, axis1, axis2, axis3):\n",
    "  A = te.placeholder((m, n), name=\"A\")\n",
    "  B = te.compute((m, n), lambda i, j: A[i, j], name=\"B\")\n",
    "  s = te.create_schedule(B.op)\n",
    "  # tile to four axes first: (i.outer, j.outer, i.inner, j.inner)\n",
    "  axes4 = s[B].tile(B.op.axis[0], B.op.axis[1], x_factor=10, y_factor=5)\n",
    "  s[B].reorder(axes4[axis0], axes4[axis1], axes4[axis2], axes4[axis3])\n",
    "  print(tvm.lower(s, [A, B], simple_mode=True))\n",
    "\n",
    "test_reorder(0, 1, 2, 3) # no change\n",
    "test_reorder(2, 1, 0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SchedulePrimitives::Gpu::Bind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bind():\n",
    "  A = te.placeholder((n,), name=\"A\")\n",
    "  B = te.compute(A.shape, lambda i: A[i], name=\"B\")\n",
    "  s = te.create_schedule(B.op)\n",
    "  bx, tx = s[B].split(B.op.axis[0], factor=64)\n",
    "  s[B].bind(bx, te.thread_axis(\"blockIdx.x\"))\n",
    "  s[B].bind(tx, te.thread_axis(\"threadIdx.x\"))\n",
    "  print(tvm.lower(s, [A, B], simple_mode=True))\n",
    "test_bind()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SchedulePrimitives::Compute_At\n",
    "\n",
    "移动一个Compute Stage 到指定的计算指定维度中，看起来可以用在 Fusion 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_compute_at(axis):\n",
    "  A = te.placeholder((m, n), name=\"A\")\n",
    "  B = te.compute((m, n), lambda i, j: A[i, j] + 1, name=\"B\")\n",
    "  C = te.compute((m, n), lambda i, j: B[i, j] * 2, name=\"C\")\n",
    "  s = te.create_schedule(C.op)\n",
    "  # move computation of B into the first axis of computation of C\n",
    "  s[B].compute_at(s[C], C.op.axis[axis]) \n",
    "  print(tvm.lower(s, [A, B, C], simple_mode=True))\n",
    "\n",
    "test_compute_at(-1)\n",
    "test_compute_at(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SchedulePrimitives::Compute_Inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_compute_inline():\n",
    "  A = te.placeholder((m,), name=\"A\")\n",
    "  B = te.compute((m,), lambda i: A[i] + 1, name=\"B\")\n",
    "  C = te.compute((m,), lambda i: B[i] * 2, name=\"C\")\n",
    "  s = te.create_schedule(C.op)\n",
    "  # mark one stage as inline\n",
    "  s[B].compute_inline()\n",
    "  print(tvm.lower(s, [A, B, C], simple_mode=True))\n",
    "\n",
    "test_compute_inline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SchedulePrimitives::Compute_Root\n",
    "\n",
    "将一个计算移动到根上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_compute_root():\n",
    "  A = te.placeholder((m,), name=\"A\")\n",
    "  B = te.compute((m,), lambda i: A[i] + 1, name=\"B\")\n",
    "  C = te.compute((m,), lambda i: B[i] * 2, name=\"C\")\n",
    "  s = te.create_schedule(C.op)\n",
    "  s[B].compute_at(s[C], C.op.axis[0])\n",
    "  # move computation of one stage to the root\n",
    "  s[B].compute_root()\n",
    "  print(tvm.lower(s, [A, B, C], simple_mode=True))\n",
    "\n",
    "test_compute_root()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e5d003a34d96501b815919cdb43990f793a06da60803b68ddd0500cde71cfe2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
