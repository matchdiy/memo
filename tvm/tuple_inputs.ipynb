{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Compute and Reduce with Tuple Inputs\n",
        "**Author**: [Ziheng Jiang](https://github.com/ZihengJiang)\n",
        "\n",
        "Often we want to compute multiple outputs with the same shape within\n",
        "a single loop or perform reduction that involves multiple values like\n",
        ":code:`argmax`. These problems can be addressed by tuple inputs.\n",
        "\n",
        "In this tutorial, we will introduce the usage of tuple inputs in TVM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, print_function\n",
        "\n",
        "\n",
        "import tvm\n",
        "from tvm import te\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Describe Batchwise Computation\n",
        "For operators which have the same shape, we can put them together as\n",
        "the inputs of :any:`te.compute`, if we want them to be scheduled\n",
        "together in the next schedule procedure.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "@main = primfn(A0_1: handle, A1_1: handle, B_2: handle, B_3: handle) -> ()\n",
            "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
            "  buffers = {A0: Buffer(A0_2: Pointer(float32), float32, [(stride: int32*m: int32)], [], type=\"auto\"),\n",
            "             A1: Buffer(A1_2: Pointer(float32), float32, [(stride_1: int32*m)], [], type=\"auto\"),\n",
            "             B: Buffer(B_4: Pointer(float32), float32, [(stride_2: int32*m)], [], type=\"auto\"),\n",
            "             B_1: Buffer(B_5: Pointer(float32), float32, [(stride_3: int32*m)], [], type=\"auto\")}\n",
            "  buffer_map = {A0_1: A0, A1_1: A1, B_2: B, B_3: B_1}\n",
            "  preflattened_buffer_map = {A0_1: A0_3: Buffer(A0_2, float32, [m, n: int32], [stride, stride_4: int32], type=\"auto\"), A1_1: A1_3: Buffer(A1_2, float32, [m, n], [stride_1, stride_5: int32], type=\"auto\"), B_2: B_6: Buffer(B_4, float32, [m, n], [stride_2, stride_6: int32], type=\"auto\"), B_3: B_7: Buffer(B_5, float32, [m, n], [stride_3, stride_7: int32], type=\"auto\")} {\n",
            "  for (i: int32, 0, m) {\n",
            "    for (j: int32, 0, n) {\n",
            "      B[((i*stride_2) + (j*stride_6))] = (A0[((i*stride) + (j*stride_4))] + 2f32)\n",
            "      B_1[((i*stride_3) + (j*stride_7))] = (A1[((i*stride_1) + (j*stride_5))]*3f32)\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n = te.var(\"n\")\n",
        "m = te.var(\"m\")\n",
        "A0 = te.placeholder((m, n), name=\"A0\")\n",
        "A1 = te.placeholder((m, n), name=\"A1\")\n",
        "B0, B1 = te.compute((m, n), lambda i, j: (A0[i, j] + 2, A1[i, j] * 3), name=\"B\")\n",
        "\n",
        "# The generated IR code would be:\n",
        "s = te.create_schedule(B0.op)\n",
        "print(tvm.lower(s, [A0, A1, B0, B1], simple_mode=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Describe Reduction with Collaborative Inputs\n",
        "Sometimes, we require multiple inputs to express some reduction\n",
        "operators, and the inputs will collaborate together, e.g. :code:`argmax`.\n",
        "In the reduction procedure, :code:`argmax` need to compare the value of\n",
        "operands, also need to keep the index of operand. It can be expressed\n",
        "with :py:func:`te.comm_reducer` as below:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "@main = primfn(idx_1: handle, val_1: handle, T_2: handle, T_3: handle) -> ()\n",
            "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
            "  buffers = {idx: Buffer(idx_2: Pointer(int32), int32, [(stride: int32*m: int32)], [], type=\"auto\"),\n",
            "             val: Buffer(val_2: Pointer(int32), int32, [(stride_1: int32*m)], [], type=\"auto\"),\n",
            "             T: Buffer(T_4: Pointer(int32), int32, [(stride_2: int32*m)], [], type=\"auto\"),\n",
            "             T_1: Buffer(T_5: Pointer(int32), int32, [(stride_3: int32*m)], [], type=\"auto\")}\n",
            "  buffer_map = {idx_1: idx, val_1: val, T_2: T, T_3: T_1}\n",
            "  preflattened_buffer_map = {idx_1: idx_3: Buffer(idx_2, int32, [m, n: int32], [stride, stride_4: int32], type=\"auto\"), val_1: val_3: Buffer(val_2, int32, [m, n], [stride_1, stride_5: int32], type=\"auto\"), T_2: T_6: Buffer(T_4, int32, [m], [stride_2], type=\"auto\"), T_3: T_7: Buffer(T_5, int32, [m], [stride_3], type=\"auto\")} {\n",
            "  for (i: int32, 0, m) {\n",
            "    T[(i*stride_2)] = -1\n",
            "    T_1[(i*stride_3)] = -2147483648\n",
            "    for (k: int32, 0, n) {\n",
            "      T[(i*stride_2)] = @tir.if_then_else((val[((i*stride_1) + (k*stride_5))] <= T_1[(i*stride_3)]), T[(i*stride_2)], idx[((i*stride) + (k*stride_4))], dtype=int32)\n",
            "      T_1[(i*stride_3)] = @tir.if_then_else((val[((i*stride_1) + (k*stride_5))] <= T_1[(i*stride_3)]), T_1[(i*stride_3)], val[((i*stride_1) + (k*stride_5))], dtype=int32)\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# x and y are the operands of reduction, both of them is a tuple of index\n",
        "# and value.\n",
        "def fcombine(x, y):\n",
        "    lhs = tvm.tir.Select((x[1] >= y[1]), x[0], y[0]) ### value\n",
        "    rhs = tvm.tir.Select((x[1] >= y[1]), x[1], y[1]) ### index\n",
        "    return lhs, rhs\n",
        "\n",
        "\n",
        "# our identity element also need to be a tuple, so `fidentity` accepts\n",
        "# two types as inputs.\n",
        "def fidentity(t0, t1):\n",
        "    return tvm.tir.const(-1, t0), tvm.te.min_value(t1) ### t0=index, t1=value\n",
        "\n",
        "\n",
        "argmax = te.comm_reducer(fcombine, fidentity, name=\"argmax\")\n",
        "\n",
        "# describe the reduction computation\n",
        "m = te.var(\"m\")\n",
        "n = te.var(\"n\")\n",
        "idx = te.placeholder((m, n), name=\"idx\", dtype=\"int32\")\n",
        "val = te.placeholder((m, n), name=\"val\", dtype=\"int32\")\n",
        "k = te.reduce_axis((0, n), \"k\")\n",
        "T0, T1 = te.compute((m,), lambda i: argmax((idx[i, k], val[i, k]), axis=k), name=\"T\")\n",
        "\n",
        "# the generated IR code would be:\n",
        "s = te.create_schedule(T0.op)\n",
        "print(tvm.lower(s, [idx, val, T0, T1], simple_mode=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>For ones who are not familiar with reduction, please refer to\n",
        "  `general-reduction`.</p></div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Schedule Operation with Tuple Inputs\n",
        "It is worth mentioning that although you will get multiple outputs\n",
        "with one batch operation, but they can only be scheduled together\n",
        "in terms of operation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "@main = primfn(A0_1: handle, A1_1: handle, C_1: handle) -> ()\n",
            "  attr = {\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True}\n",
            "  buffers = {A0: Buffer(A0_2: Pointer(float32), float32, [(stride: int32*m: int32)], [], type=\"auto\"),\n",
            "             A1: Buffer(A1_2: Pointer(float32), float32, [(stride_1: int32*m)], [], type=\"auto\"),\n",
            "             C: Buffer(C_2: Pointer(float32), float32, [(stride_2: int32*m)], [], type=\"auto\")}\n",
            "  buffer_map = {A0_1: A0, A1_1: A1, C_1: C}\n",
            "  preflattened_buffer_map = {A0_1: A0_3: Buffer(A0_2, float32, [m, n: int32], [stride, stride_3: int32], type=\"auto\"), A1_1: A1_3: Buffer(A1_2, float32, [m, n], [stride_1, stride_4: int32], type=\"auto\"), C_1: C_3: Buffer(C_2, float32, [m, n], [stride_2, stride_5: int32], type=\"auto\")} {\n",
            "  allocate(B.v0: Pointer(global float32), float32, [n]), storage_scope = global;\n",
            "  allocate(B.v1: Pointer(global float32), float32, [n]), storage_scope = global;\n",
            "  for (i: int32, 0, m) {\n",
            "    for (j: int32, 0, n) {\n",
            "      B.v0_1: Buffer(B.v0, float32, [n], [])[j] = (A0[((i*stride) + (j*stride_3))] + 2f32)\n",
            "      B.v1_1: Buffer(B.v1, float32, [n], [])[j] = (A0[((i*stride) + (j*stride_3))]*3f32)\n",
            "    }\n",
            "    for (j_1: int32, 0, n) {\n",
            "      C[((i*stride_2) + (j_1*stride_5))] = (A1[((i*stride_1) + (j_1*stride_4))] + B.v0_1[j_1])\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[17:03:24] /home/jia/Workspace/tvm/src/te/schedule/bound.cc:119: not in feed graph consumer = compute(B, body=[(A0[i, j] + 2f), (A0[i, j]*3f)], axis=[iter_var(i, range(min=0, ext=m)), iter_var(j, range(min=0, ext=n))], reduce_axis=[], tag=, attrs={})\n"
          ]
        }
      ],
      "source": [
        "n = te.var(\"n\")\n",
        "m = te.var(\"m\")\n",
        "A0 = te.placeholder((m, n), name=\"A0\")\n",
        "B0, B1 = te.compute((m, n), lambda i, j: (A0[i, j] + 2, A0[i, j] * 3), name=\"B\")\n",
        "A1 = te.placeholder((m, n), name=\"A1\")\n",
        "C = te.compute((m, n), lambda i, j: A1[i, j] + B0[i, j], name=\"C\")\n",
        "\n",
        "s = te.create_schedule(C.op)\n",
        "s[B0].compute_at(s[C], C.op.axis[0])\n",
        "# as you can see in the below generated IR code:\n",
        "print(tvm.lower(s, [A0, A1, C], simple_mode=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "This tutorial introduces the usage of tuple inputs operation.\n",
        "\n",
        "- Describe normal batchwise computation.\n",
        "- Describe reduction operation with tuple inputs.\n",
        "- Notice that you can only schedule computation in terms of operation instead of tensor.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.13 ('py38')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "221bae69870c1675c4cfc152c4d60c3a5cfbb0e1cf1a5072332d9dded6c10f66"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
